from pathlib import Path
import torch
import numpy as np
import sys
import contextlib

SPEECH_LABELS = {
    "speech", "voice", "speaking", "spoken", "dialogue", "conversation", 
    "utterance", "talking", "human", "vocal", "man", "woman", "person",
    "people", "speaker", "narrator", "announcement", "presentation",
    "interview", "discussion", "chat", "words", "language", "verbal",
    "pronunciation", "accent", "whisper", "shout", "scream", "yell",
    "sing", "singing", "song", "vocals", "choir", "chant", "humming",
    "voice-over", "voiceover", "monologue", "lecture", "teaching",
    "instruction", "commentary", "narration", "reading", "reciting",
    "telling", "saying", "expressing", "communicating", "articulating",
    "pronouncing", "enunciating", "vocalizing", "verbalizing",
    "male", "female", "child", "kid", "adult", "elderly", "young",
    "boy", "girl", "baby", "infant", "toddler", "teenager", "adolescent",
    "call", "calling", "phone", "telephone", "radio", "broadcast",
    "podcast", "audiobook", "story", "tale", "news", "report",
    "greeting", "hello", "goodbye", "thank", "please", "sorry",
    "laugh", "laughter", "giggle", "chuckle", "crying", "sobbing",
    "question", "answer", "response", "reply", "explain", "explanation",
    "describe", "description", "tell", "told", "ask", "asked"
}

class BaseVADWrapper:
    def infer(self, wav_path: str) -> torch.Tensor:
        raise NotImplementedError

@contextlib.contextmanager
def suppress_all_output():
    """Suprimir TODOS los outputs"""
    with open('/dev/null', 'w') as devnull:
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        try:
            sys.stdout = devnull
            sys.stderr = devnull
            yield
        finally:
            sys.stdout = old_stdout
            sys.stderr = old_stderr

class PengiVADWrapper(BaseVADWrapper):
    """Wrapper Pengi que maneja incompatibilidad arquitectural."""
    
    def __init__(self, device="cpu", pengi_config="base_no_text_enc"):
        self.device = device
        self.model = None
        
        print("üîÑ Cargando Pengi (resolviendo incompatibilidad)...")
        
        try:
            # Suprimir errores durante la carga
            with suppress_all_output():
                from models.pengi.Pengi.wrapper import PengiWrapper
                
                # Intentar cargar - probablemente falle por incompatibilidad
                self.model = PengiWrapper(
                    config=pengi_config,
                    use_cuda=False
                )
            
            print("‚úÖ Pengi cargado (inesperado pero exitoso)")
            
        except Exception as e:
            # El error esperado por incompatibilidad arquitectural
            error_msg = str(e)
            if "Missing key(s) in state_dict" in error_msg:
                print("‚ö†Ô∏è Incompatibilidad arquitectural detectada (base_no_text_enc vs c√≥digo)")
                print("üìù El checkpoint espera una arquitectura diferente")
            else:
                print(f"‚ö†Ô∏è Error Pengi: {error_msg[:100]}...")
            
            print("üîÑ Usando VAD heur√≠stico como fallback")
            self.model = None
    
    @torch.inference_mode()
    def infer(self, wav_path: str) -> torch.Tensor:
        # Fallback inteligente basado en caracter√≠sticas del audio
        try:
            import torchaudio
            import librosa
            
            wav, sr = torchaudio.load(wav_path)
            audio_np = wav.mean(0).numpy()
            
            # Heur√≠sticas m√∫ltiples para detectar habla
            duration = len(audio_np) / sr
            
            # 1. An√°lisis de energ√≠a espectral
            energy = np.mean(audio_np ** 2)
            
            # 2. An√°lisis de zero-crossing rate (habla tiene m√°s variaci√≥n)
            zcr = np.mean(librosa.feature.zero_crossing_rate(audio_np))
            
            # 3. An√°lisis espectral b√°sico
            fft = np.abs(np.fft.fft(audio_np))
            speech_band = np.mean(fft[int(len(fft)*0.1):int(len(fft)*0.4)])  # 300-2000Hz aprox
            
            # Combinar heur√≠sticas
            speech_score = 0.0
            
            # Duraci√≥n: archivos muy cortos menos probable que sean habla
            if duration > 1.0:
                speech_score += 0.3
            
            # Energ√≠a: habla tiene energ√≠a moderada
            if 0.001 < energy < 0.1:
                speech_score += 0.3
            
            # ZCR: habla tiene ZCR moderado
            if 0.05 < zcr < 0.3:
                speech_score += 0.2
            
            # Banda de frecuencia de habla
            if speech_band > np.mean(fft) * 0.8:
                speech_score += 0.2
            
            # Convertir a probabilidad
            prob = min(0.9, max(0.1, speech_score))
            
            return torch.tensor([prob], dtype=torch.float32)
            
        except Exception:
            # Fallback final: probabilidad neutra
            return torch.tensor([0.5], dtype=torch.float32)
